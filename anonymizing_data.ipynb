{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3546361-4e53-4134-be1b-763c9c2ac11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Schema:\n",
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      "\n",
      "\n",
      "Sample of Original Data:\n",
      "+----------+---------+------------------------------------+-------------+\n",
      "|first_name|last_name|address                             |date_of_birth|\n",
      "+----------+---------+------------------------------------+-------------+\n",
      "|Matthew   |Rogers   |8491 Pine Way, Salem, CA 81643      |1999-02-06   |\n",
      "|Nichole   |Hobbs    |4176 Cedar Ave, Bristol, CT 81309   |1957-12-11   |\n",
      "|Jeremy    |Perez    |3367 Elm Ave, Franklin, GA 47854    |1956-01-17   |\n",
      "|Lori      |Nicholson|8897 Maple Ave, Greenville, CA 17563|1969-06-10   |\n",
      "|David     |Martinez |5404 Elm Ave, Franklin, DE 50127    |1993-12-19   |\n",
      "+----------+---------+------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Anonymized data size: 2.36 GB\n",
      "\n",
      "Sample of Anonymized Data:\n",
      "+----------+---------+---------------------------------+-------------+\n",
      "|first_name|last_name|address                          |date_of_birth|\n",
      "+----------+---------+---------------------------------+-------------+\n",
      "|M*****    |R*****   |XXX Pine Way, Salem, CA XXX      |1999-02-06   |\n",
      "|N*****    |H*****   |XXX Cedar Ave, Bristol, CT XXX   |1957-12-11   |\n",
      "|J*****    |P*****   |XXX Elm Ave, Franklin, GA XXX    |1956-01-17   |\n",
      "|L*****    |N*****   |XXX Maple Ave, Greenville, CA XXX|1969-06-10   |\n",
      "|D*****    |M*****   |XXX Elm Ave, Franklin, DE XXX    |1993-12-19   |\n",
      "+----------+---------+---------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, substring, concat, lit\n",
    "from pyspark.sql.types import StringType\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"DataAnonymization\").getOrCreate()\n",
    "\n",
    "# Function to get file size\n",
    "def get_file_size(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return 0\n",
    "    result = subprocess.run(['du', '-sb', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error getting file size: {result.stderr.decode()}\")\n",
    "        return 0\n",
    "    return int(result.stdout.split()[0])\n",
    "\n",
    "# Set parameters\n",
    "input_path = \"randomly_generated_large_dataset\"\n",
    "output_path = \"final_anonymized_data\"\n",
    "target_size = 2* 1024 * 1024 * 1024   \n",
    "\n",
    "# Read the original data\n",
    "df = spark.read.csv(input_path, header=True, inferSchema=True)\n",
    "\n",
    "# Print schema and sample of original data\n",
    "print(\"Original Data Schema:\")\n",
    "df.printSchema()\n",
    "print(\"\\nSample of Original Data:\")\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# Anonymization functions\n",
    "def anonymize_name(name):\n",
    "    return concat(substring(name, 1, 1), lit('*' * 5))\n",
    "\n",
    "@udf(StringType())\n",
    "def anonymize_address(address):\n",
    "    words = address.split()\n",
    "    anonymized_words = ['XXX' if any(c.isdigit() for c in word) else word for word in words]\n",
    "    return ' '.join(anonymized_words)\n",
    "\n",
    "# Apply anonymization\n",
    "anonymized_df = df.select(\n",
    "    anonymize_name(col(\"first_name\")).alias('first_name'),\n",
    "    anonymize_name(col(\"last_name\")).alias('last_name'),\n",
    "    anonymize_address(col(\"address\")).alias('address'),\n",
    "    col(\"date_of_birth\")\n",
    ")\n",
    "\n",
    "# Write anonymized data\n",
    "anonymized_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# Check size and print sample\n",
    "current_size = get_file_size(output_path)\n",
    "print(f\"\\nAnonymized data size: {current_size / (1024*1024*1024):.2f} GB\")\n",
    "\n",
    "print(\"\\nSample of Anonymized Data:\")\n",
    "anonymized_df.show(5, truncate=False)\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde1e1c-5450-40ac-8f75-6abf7555b861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
